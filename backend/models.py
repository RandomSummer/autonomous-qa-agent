"""
Pydantic data models for the QA Agent system.
Defines structure for documents, test cases, scripts, and API requests/responses.
"""

from typing import List, Optional, Dict, Any
from pydantic import BaseModel, Field
from datetime import datetime


# ============================================================================
# Document Models - For handling uploaded documents and their chunks
# ============================================================================

class DocumentMetadata(BaseModel):
    """
    Metadata for uploaded documents.
    Tracks file information for traceability.
    """
    filename: str = Field(..., description="Name of the uploaded file")
    file_type: str = Field(..., description="File extension (md, txt, html, etc.)")
    size_bytes: int = Field(..., description="File size in bytes")
    upload_timestamp: datetime = Field(default_factory=datetime.now, description="When file was uploaded")
    num_chunks: Optional[int] = Field(None, description="Number of chunks this document was split into")


class DocumentChunk(BaseModel):
    """
    Represents a single chunk of a document after splitting.
    Used for embedding and vector storage.
    """
    chunk_id: str = Field(..., description="Unique identifier for this chunk")
    text: str = Field(..., description="The actual text content")
    source_document: str = Field(..., description="Original document filename")
    chunk_index: int = Field(..., description="Position in the document (0-based)")
    total_chunks: int = Field(..., description="Total number of chunks from this document")
    metadata: Optional[Dict[str, Any]] = Field(default_factory=dict, description="Additional metadata")


# ============================================================================
# Test Case Models - For generated test cases
# ============================================================================

class TestCase(BaseModel):
    """
    Structured test case generated by the AI agent.
    
    CRITICAL: grounded_in field ensures all test cases reference source documents.
    This prevents hallucinations and enables traceability.
    """
    test_id: str = Field(..., description="Unique test case ID (e.g., TC-001)")
    feature: str = Field(..., description="Feature being tested")
    test_scenario: str = Field(..., description="Detailed description of what is being tested")
    test_type: str = Field(..., description="Type: positive, negative, or edge_case")
    preconditions: str = Field(..., description="Setup required before running the test")
    test_steps: List[str] = Field(..., description="Step-by-step actions to perform")
    expected_result: str = Field(..., description="What should happen when test passes")
    grounded_in: str = Field(
        ..., 
        description="Source document(s) this test case is based on - REQUIRED for traceability"
    )
    
    class Config:
        json_schema_extra = {
            "example": {
                "test_id": "TC-001",
                "feature": "Discount Code Validation",
                "test_scenario": "Verify that valid discount code SAVE15 applies 15% discount",
                "test_type": "positive",
                "preconditions": "User has items in cart, checkout page is loaded",
                "test_steps": [
                    "Navigate to checkout page",
                    "Enter discount code 'SAVE15' in the code field",
                    "Click 'Apply' button",
                    "Verify discount is applied"
                ],
                "expected_result": "15% discount is applied to cart total, success message displayed",
                "grounded_in": "product_specs.md"
            }
        }


class TestCaseResponse(BaseModel):
    """
    Response wrapper for test case generation.
    Includes success status and list of generated test cases.
    """
    success: bool = Field(..., description="Whether test case generation succeeded")
    message: str = Field(..., description="Status message or error description")
    test_cases: List[TestCase] = Field(default_factory=list, description="Generated test cases")
    total_cases: int = Field(0, description="Total number of test cases generated")


# ============================================================================
# Selenium Script Models - For generated automation scripts
# ============================================================================

class SeleniumScript(BaseModel):
    """
    Generated Selenium Python script with metadata.
    Contains executable code for browser automation.
    """
    test_id: str = Field(..., description="Associated test case ID")
    script_content: str = Field(..., description="The actual Python/Selenium code")
    filename: str = Field(..., description="Suggested filename for the script")
    description: str = Field(..., description="What this script does")
    generated_at: datetime = Field(default_factory=datetime.now, description="When script was generated")
    grounded_in: Optional[str] = Field(None, description="Source documents used")
    dependencies: List[str] = Field(default_factory=lambda: ["selenium", "webdriver-manager"], description="Required Python packages")


class ScriptGenerationRequest(BaseModel):
    """
    Request model for generating Selenium scripts.
    """
    test_case: TestCase = Field(..., description="Test case object to generate script for")
    html_content: Optional[str] = Field(None, description="HTML content for selector extraction")
    base_url: Optional[str] = Field("http://localhost", description="Base URL for the application")


class ScriptGenerationResponse(BaseModel):
    """
    Response wrapper for script generation.
    """
    success: bool = Field(..., description="Whether script generation succeeded")
    message: str = Field(..., description="Status message or error description")
    script: Optional[SeleniumScript] = Field(None, description="Generated script if successful")
    file_path: Optional[str] = Field(None, description="Where script was saved")


# ============================================================================
# RAG Query Models - For RAG service requests/responses
# ============================================================================

class RAGQueryRequest(BaseModel):
    """
    Request model for RAG queries.
    """
    query: str = Field(..., description="User query or question")
    system_prompt: Optional[str] = Field(None, description="Custom system prompt for LLM")
    n_results: Optional[int] = Field(5, description="Number of chunks to retrieve")
    temperature: Optional[float] = Field(0.1, description="LLM temperature (0=deterministic, 1=creative)")


class RAGQueryResponse(BaseModel):
    """
    Response model for RAG queries.
    """
    success: bool = Field(..., description="Whether query succeeded")
    response: str = Field(..., description="Generated response from LLM")
    context: str = Field(..., description="Retrieved context from vector DB")
    num_chunks: int = Field(..., description="Number of chunks used")
    sources: List[str] = Field(default_factory=list, description="Source documents referenced")


# ============================================================================
# Document Upload Models - For document ingestion API
# ============================================================================

class DocumentUploadResponse(BaseModel):
    """
    Response after uploading and processing documents.
    """
    success: bool = Field(..., description="Whether upload/processing succeeded")
    message: str = Field(..., description="Status message")
    filename: str = Field(..., description="Uploaded filename")
    num_chunks: int = Field(0, description="Number of chunks created")
    file_type: str = Field(..., description="Detected file type")


class VectorStoreStats(BaseModel):
    """
    Statistics about the vector store.
    """
    total_documents: int = Field(..., description="Number of documents in vector DB")
    total_chunks: int = Field(..., description="Number of chunks in vector DB")
    collection_name: str = Field(..., description="ChromaDB collection name")
    embedding_model: str = Field(..., description="Model used for embeddings")

# ============================================================================
# API Response Models - For FastAPI endpoints
# ============================================================================

class HealthResponse(BaseModel):
    """
    Health check response for API status.
    """
    status: str = Field(..., description="API status: healthy or unhealthy")
    groq_api_configured: bool = Field(..., description="Whether Groq API key is configured")
    vector_db_initialized: bool = Field(..., description="Whether vector DB has data")


class KnowledgeBaseStatus(BaseModel):
    """
    Status response for knowledge base operations.
    """
    success: bool = Field(..., description="Whether operation succeeded")
    message: str = Field(..., description="Status message")
    total_documents: int = Field(0, description="Number of documents processed")
    total_chunks: int = Field(0, description="Number of chunks created")
    documents_processed: List[str] = Field(default_factory=list, description="List of processed document names")


class TestCaseRequest(BaseModel):
    """
    Request model for test case generation.
    """
    query: str = Field(..., description="User query describing what to test")
    include_negative: bool = Field(True, description="Whether to include negative test cases")


class UploadResponse(BaseModel):
    """
    Response model for file uploads.
    """
    success: bool = Field(..., description="Whether upload succeeded")
    message: str = Field(..., description="Status message")
    filename: str = Field(..., description="Uploaded filename")
    file_path: str = Field("", description="Path where file was saved")
